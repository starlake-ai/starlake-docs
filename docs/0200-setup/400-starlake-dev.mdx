---
id: starlake-dev
title: "Set Up Starlake with Airflow or Dagster (Docker Compose)"
description: "Deploy Starlake with Airflow or Dagster using Docker Compose. Clone, run docker compose up, and access the Starlake UI. Kubernetes and cloud deployments also available."
keywords: [airflow setup, dagster setup, starlake orchestration, docker compose, data pipeline orchestration, starlake airflow, starlake dagster]
---

import Head from '@docusaurus/Head';

<Head>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "FAQPage",
      "mainEntity": [
        {
          "@type": "Question",
          "name": "How do I set up Starlake with Airflow?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Clone the starlake-docker repository, navigate to the docker folder, and run 'docker compose up'. Airflow is automatically installed and configured. Access the Starlake UI at http://localhost."
          }
        },
        {
          "@type": "Question",
          "name": "How do I set up Starlake with Dagster instead of Airflow?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Use the Dagster-specific compose file: 'docker compose -f docker-compose-dagster.yml up'. Dagster replaces Airflow as the orchestrator in this configuration."
          }
        },
        {
          "@type": "Question",
          "name": "Can I deploy Starlake on Kubernetes?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Kubernetes deployment is available. Contact the Starlake engineering team on Slack to get the latest Helm chart."
          }
        },
        {
          "@type": "Question",
          "name": "What orchestration tools does Starlake support?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Starlake supports Airflow and Dagster. Both are pre-configured in the Docker Compose setup."
          }
        },
        {
          "@type": "Question",
          "name": "How do I mount external projects in the Starlake Docker setup?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "On macOS, run setup_mac_nfs.sh to expose your folder via NFS. Then modify the docker-compose.yml to use the NFS volume mount instead of the default volume. External project folders must contain the Starlake project structure (metadata/ etc.)."
          }
        }
      ]
    })}
  </script>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "HowTo",
      "name": "How to set up Starlake with Airflow or Dagster",
      "step": [
        {"@type": "HowToStep", "name": "Clone the starlake-docker repository", "text": "Run 'git clone https://github.com/starlake-ai/starlake-docker.git' to download the Docker Compose configuration."},
        {"@type": "HowToStep", "name": "Navigate to the docker folder", "text": "Run 'cd starlake-docker/docker' to enter the directory containing the compose files."},
        {"@type": "HowToStep", "name": "Start the stack with Airflow or Dagster", "text": "Run 'docker compose up' for Airflow, or 'docker compose -f docker-compose-dagster.yml up' for Dagster. Both orchestrators are pre-configured."},
        {"@type": "HowToStep", "name": "Access the Starlake UI", "text": "Open http://localhost in your browser. To use a different port, set the SL_UI_PORT environment variable before running docker compose."}
      ]
    })}
  </script>
</Head>

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Starlake can be deployed with Airflow or Dagster as the orchestration engine using a pre-configured Docker Compose setup. The `starlake-docker` repository provides compose files that install and configure Starlake, the web UI, and the chosen orchestrator in a single command. Deployment is also available on Kubernetes and on AWS, GCP, or Azure via Terraform.

## How to Set Up Starlake with Airflow or Dagster (Step-by-Step)

1. **Clone the starlake-docker repository** â€” Run `git clone https://github.com/starlake-ai/starlake-docker.git`.
2. **Navigate to the docker folder** â€” Run `cd starlake-docker/docker`.
3. **Start the stack with Airflow or Dagster** â€” Run `docker compose up` for Airflow, or `docker compose -f docker-compose-dagster.yml up` for Dagster.
4. **Access the Starlake UI** â€” Open `http://localhost` in your browser. Set `SL_UI_PORT` to change the port.

---

:::tip
This is a Docker-based setup for Starlake with Airflow or Dagster pre-configured.

:::

This is ideal for developers and data engineers
who want to quickly set up a data pipeline environment without the need to separately install and configure Airflow or Dagster.
Airflow and Dagster will be automatically installed and configured as part of the Starlake setup.
It provides a streamlined setup process, allowing you to focus on building and managing your data projects
rather than dealing with infrastructure configurations.

The core project is open source and can be found at [starlake-ai/starlake](https://github.com/starlake-ai/starlake)

Starlake may be installed on your own infrastructure, whether on your on-premises or in the cloud.

You may install it on a server or a developer workstation using the docker-compose file provided to run the Starlake UI with Airflow or Dagster.
Three installation options are available for the following platforms:
- Starlake on Docker Compose
- Starlake on Kubernetes
- Starlake on AWS / GCP / Azure



<Tabs groupId="small-data-setup-options">
<TabItem value="docker-compose" label="ðŸ³ Starlake on Docker Compose">
## Starlake on Docker Compose

1. Clone this repository
```bash
git clone https://github.com/starlake-ai/starlake-docker.git
```

2. Change directory to the cloned repository
```bash
cd starlake-docker/docker
```

3. Run the following command to start Starlake UI with Airflow
```bash
docker compose up
```

to run Starlake UI with Dagster, run the following command
```bash
docker compose -f docker-compose-dagster.yml up
```


To run on a different port, set the `SL_UI_PORT` environment variable. For example, to run on port 8080, run the following command
```bash
SL_UI_PORT=8080 docker-compose up
```

4. Open your browser and navigate to `http://localhost` or if you chose a different port `http://localhost:$SL_UI_PORT` to access Starlake UI

That's it! You have successfully started Starlake on your own infrastructure.

### Mounting external projects

If you have any starlake container projects and want to mount it:
- run `setup_mac_nfs.sh` if you are on mac in order to expose your folder via NFS.
  Modify the root folder to share if necessary. By default it is set to /user.
  This change is not specific to starlake and may be used in other container.
- comment `- external_projects_data:/external_projects`
- uncomment `- starlake-prj-nfs-mount:/external_projects`
- go to the end of the file and modify the path of the volume to point to the starlake container folder

Starlake container folder should contain the starlake project folder:

```
 my_container_to_mount
   |
    - sl_project_1
        |
         - metadata
         - ...
   |
    - sl_project_2
        |
         - metadata
         - ...
```

If you have many container projects, create as many volume as needed.

#### Limit

- Currently, we cannot mount the starlake projects directory directly under the mounted `/external_projects`. Subfolders of the mounted external project can't be accessed correctly.
- This feature has been tested only on MacOS and linux at the moment


### Stopping Starlake UI
To stop Starlake UI, run the following command in the same directory
```bash
docker compose down
```

</TabItem>
<TabItem value="k8s" label="&#x2752; Starlake on Kubernetes">

Please contact our engineering team on [Slack](https://starlakeai.slack.com) to get the latest Helm chart for Starlake on Kubernetes.

</TabItem>

<TabItem value="cloud" label="&#x2601; Starlake on  AWS / GCP / Azure">

Please contact our engineering team on [Slack](https://starlakeai.slack.com) to get the latest Terraform scripts for Starlake on AWS / GCP / Azure.

</TabItem>
</Tabs>

## Frequently Asked Questions

### How do I set up Starlake with Airflow?
Clone the `starlake-docker` repository, navigate to the `docker` folder, and run `docker compose up`. Airflow is automatically installed and configured. Access the Starlake UI at `http://localhost`.

### How do I set up Starlake with Dagster instead of Airflow?
Use the Dagster-specific compose file: `docker compose -f docker-compose-dagster.yml up`. Dagster replaces Airflow as the orchestrator in this configuration.

### Can I deploy Starlake on Kubernetes?
Kubernetes deployment is available. Contact the Starlake engineering team on Slack to get the latest Helm chart.

### What orchestration tools does Starlake support?
Starlake supports Airflow and Dagster. Both are pre-configured in the Docker Compose setup.

### How do I mount external projects in the Starlake Docker setup?
On macOS, run `setup_mac_nfs.sh` to expose your folder via NFS. Then modify the `docker-compose.yml` to use the NFS volume mount instead of the default volume. External project folders must contain the Starlake project structure (`metadata/` etc.).
