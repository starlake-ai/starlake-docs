---
title: "Test Transform Tasks"
description: "Write and run unit tests for Starlake SQL transformations locally on DuckDB. Automatic SQL transpilation from BigQuery, Snowflake, or Databricks. Compare transform results against expected CSV or SQL output with detailed test reports."
keywords: [starlake, transform test, unit test, duckdb, sql transpilation, data validation, test reports, bigquery, snowflake, databricks]
---

import Head from '@docusaurus/Head';

<Head>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "HowTo",
      "name": "How to write transform tests in Starlake",
      "description": "Write and run unit tests for Starlake SQL transformations locally on DuckDB with automatic SQL transpilation from BigQuery, Snowflake, or Databricks.",
      "step": [
        {
          "@type": "HowToStep",
          "name": "Create the test directory",
          "text": "Create a test directory under metadata/tests/transform/{domain}/{table}/test-name.",
          "position": 1
        },
        {
          "@type": "HowToStep",
          "name": "Add source data files",
          "text": "Add CSV or JSONL files named domain.table.csv or domain.table.json containing the source data for all tables referenced by the transformation.",
          "position": 2
        },
        {
          "@type": "HowToStep",
          "name": "Define expected output",
          "text": "Add a _expected.csv file with static expected data or a _expected.sql file with a SQL query whose result is compared to actual output.",
          "position": 3
        },
        {
          "@type": "HowToStep",
          "name": "Run the test",
          "text": "Run 'starlake test --transform' to execute all transform tests, or 'starlake test --name domain.table.test-name' for a specific test.",
          "position": 4
        }
      ]
    })}
  </script>
</Head>

<Head>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "FAQPage",
      "mainEntity": [
        {
          "@type": "Question",
          "name": "Where to place transform tests in Starlake?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Transform tests are in metadata/tests/transform. Each test is a directory in the domain/table subdirectory."
          }
        },
        {
          "@type": "Question",
          "name": "What files make up a transform test?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "CSV or JSONL files containing initial source data (named domain.table.csv or .json), and a _expected.csv or _expected.sql file containing the expected data after transformation."
          }
        },
        {
          "@type": "Question",
          "name": "How does Starlake handle SQL dialect differences?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Starlake automatically transpiles SQL queries from the target dialect (BigQuery, Snowflake, etc.) to the DuckDB dialect before execution. No query modification is needed."
          }
        },
        {
          "@type": "Question",
          "name": "Can I use a SQL file as expected output?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Yes. The expected file can be _expected.csv (static data) or _expected.sql (a SQL query whose result is compared to the actual data)."
          }
        },
        {
          "@type": "Question",
          "name": "Where to find transform test reports?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "In test-reports/transform/test-name/. The report contains the DuckDB database (testname.db), unexpected data (not_expected.csv), and missing data (missing.csv)."
          }
        },
        {
          "@type": "Question",
          "name": "How to run only transform tests?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Use the command starlake test --transform. For a specific test: starlake test --name domain.table.test-name."
          }
        },
        {
          "@type": "Question",
          "name": "Do tests generate a visual report?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Yes. Running tests generates a complete website in the test-reports directory."
          }
        }
      ]
    })}
  </script>
</Head>

# Test Transform Tasks

Starlake transform tests validate SQL transformations locally on DuckDB with automatic dialect transpilation from BigQuery, Snowflake, or Databricks. You provide source data files and expected output (CSV or SQL), and Starlake compares schema and results. Test reports include the DuckDB database, unexpected rows, and missing rows.

## How to write transform tests

1. **Create the test directory** -- Add a directory under `metadata/tests/transform/{domain}/{table}/test-name`.
2. **Add source data files** -- Place CSV or JSONL files named `domain.table.csv` (or `.json`) for each table referenced by the transformation.
3. **Define expected output** -- Add `_expected.csv` (static data) or `_expected.sql` (SQL query whose result is compared).
4. **Run the test** -- Execute `starlake test --transform` or `starlake test --name domain.table.test-name`.

Test your transform locally before deploying to production.

Transform tasks are the second step in the data pipeline.
They are responsible for transforming the data in the database.
In this tutorial, we will test the transform tasks.


Transform tests are located in the `metadata/tests/transform` directory.

Each test is a directory located in the `domain/table` subdirectory and contains the following files:
- multiple CSV or JSONL files that will contain the initial data that will be loaded into the tables before the unit test is run.
These files should be named after the domain and table names. For example, the file for the `starbake.product` table should be named `starbake.product.json` or `starbake.product.csv`.
- a `_expected.csv` or `_expected.sql` file that contains the expected data in the table after the transform task is run.


Before running the transform, starlake will transpile your SQL statements to the Duckdb dialect before running it.
After running the transpiled SQL statement using the `starlake transform` task against local duckdb database populated by starlake using the data files present in the test directory,
Starlake will compare the schema of the table with the schema of the expected data file and will raise an error if they do not match.

The test will pass if the transform task succeeds and the data in the table matches the data in the `_expected.csv` file.

The reports of the test `test-name` are stored in the `test-reports/transform/test-name` directory and contain the following files:
- `test-reports/transform/test-name/testname.db`: the actual database after the load task is run. This database contains the following tables:
  - sl_expected: The expected data.
  - `starbake.product`: The actual data.
  - sl_expectations: The results of the execution of any the expectation related to this table.
  - audit.audit: The audit log of the transform task.
- `test-reports/transform/test-name/not_expected.csv`: the unexpected data in the actual table after the transform task is run.
- `test-reports/transform/test-name/missing.csv`: the missing data in the actual table after the transform task is run.

The test reports are generated using the `starlake test` task.

To run the transform tests without running load tests, use the following command:
```bash
starlake test --transform
```

To run a specific test use the `--name` flag:
```bash
starlake test --name starbake.product.test-name
```


Running tests will also generate a complete website report in the `test-reports` directory.


## Example: Load  summary report

![](/img/tests/load-summary.png)

## Example: Transform Test report

![](/img/tests/transform.png)

## Example: Load & Transform report

![](/img/tests/report.png)

## Frequently Asked Questions

### Where to place transform tests in Starlake?

Transform tests are in `metadata/tests/transform`. Each test is a directory in the `domain/table` subdirectory.

### What files make up a transform test?

CSV or JSONL files containing initial source data (named `domain.table.csv` or `.json`), and a `_expected.csv` or `_expected.sql` file containing the expected data after transformation.

### How does Starlake handle SQL dialect differences?

Starlake automatically transpiles SQL queries from the target dialect (BigQuery, Snowflake, etc.) to the DuckDB dialect before execution. No query modification is needed.

### Can I use a SQL file as expected output?

Yes. The expected file can be `_expected.csv` (static data) or `_expected.sql` (a SQL query whose result is compared to the actual data).

### Where to find transform test reports?

In `test-reports/transform/test-name/`. The report contains the DuckDB database (`testname.db`), unexpected data (`not_expected.csv`), and missing data (`missing.csv`).

### How to run only transform tests?

Use the command `starlake test --transform`. For a specific test: `starlake test --name domain.table.test-name`.

### Do tests generate a visual report?

Yes. Running tests generates a complete website in the `test-reports` directory.

