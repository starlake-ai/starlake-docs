---
title: "Deploy Starlake Pipelines"
description: "Deploy Starlake data pipelines to cloud environments by copying metadata to cloud storage and running load and transform commands."
keywords: [starlake, deploy, cloud deployment, docker, orchestration, data pipeline, production]
---

# Deploy Starlake Pipelines

## Running your project
Deploying your project is as simple as copying your metadata folder to a cloud storage bucket
and run any of the load / transform command from the `starlake` docker container running on any cloud provider.

:::note
Make sure you use environment variables to abstract your project
from the target environment as described [here](../../configuration/environment)

In your starlake docker container make the SL_ENV and SL_ROOT env variables are set to the correct values.

:::



## Orchestrating the pipeline

To run on your orchestrator, just copy the contents of the `metadata/dags/generated` folder to your orchestrator's DAGs folder.


