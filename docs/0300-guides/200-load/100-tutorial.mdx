---
title: "Load Data into Your Data Warehouse"
description: "Step-by-step tutorial to load and validate JSON, XML and CSV files into your data warehouse using Starlake autoload and write strategies."
keywords: [starlake, load tutorial, data warehouse, autoload, CSV, JSON, XML, write strategies]
---

import Head from '@docusaurus/Head';

<Head>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "FAQPage",
      "mainEntity": [
        {
          "@type": "Question",
          "name": "What file formats does Starlake support for loading?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Starlake supports loading CSV, TSV, JSON, XML, Fixed-width, Parquet, and Avro files. The file format is auto-detected based on the file extension and content when using the autoload command."
          }
        },
        {
          "@type": "Question",
          "name": "What is the difference between autoload and load in Starlake?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "The autoload command is a shortcut that combines infer-schema, stage, and load into a single step. It automatically detects file types, infers schemas, and loads data. The manual load command requires you to run infer-schema and stage separately before loading."
          }
        },
        {
          "@type": "Question",
          "name": "Does Starlake validate data during loading?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Yes, Starlake automatically validates data against the inferred or user-defined schema during loading. Rejected records are stored in a separate audit table, and successfully validated records are loaded into the target table."
          }
        },
        {
          "@type": "Question",
          "name": "Where do files go after being loaded by Starlake?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Once loaded, files are moved to the $SL_ROOT/datasets/archive folder if the SL_ARCHIVE environment variable is set to true (which is the default). You can replay them by moving them back to the incoming folder."
          }
        }
      ]
    })}
  </script>
</Head>

<Head>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "HowTo",
      "name": "How to Load Data into a Data Warehouse with Starlake",
      "description": "Step-by-step guide to loading and validating CSV, JSON, and XML files into your data warehouse using Starlake autoload.",
      "step": [
        {
          "@type": "HowToStep",
          "name": "Prepare incoming data files",
          "text": "Run the extract step first, or copy the sample-data folder contents into $SL_ROOT/incoming/ to have files ready for loading.",
          "position": 1
        },
        {
          "@type": "HowToStep",
          "name": "Run the autoload command",
          "text": "Run 'starlake autoload' to automatically detect file types, infer schemas, stage files, and load them into target tables.",
          "position": 2
        },
        {
          "@type": "HowToStep",
          "name": "Query the loaded data",
          "text": "Open the DuckDB shell with 'duckdb datasets/duckdb.db' and run SQL queries to verify the data has been loaded correctly.",
          "position": 3
        },
        {
          "@type": "HowToStep",
          "name": "Optionally use manual load workflow",
          "text": "Instead of autoload, you can run 'starlake infer-schema', then 'starlake stage', then 'starlake load' for more control over each step.",
          "position": 4
        }
      ]
    })}
  </script>
</Head>

# Load Data into Your Data Warehouse

Load and validate, in one shot or incrementally, JSON, XML and CSV files into your datawarehouse using different write strategies.

## Prerequisites

If you skipped the extract step above, copy the folder and its files present in `$SL_ROOT/sample-data/` to the `$SL_ROOT/incoming/` folder.


The folder name `starbake` will be translated in to a schema name (dataset in BigQuery) in the datawarehouse.

The files in the folder will be loaded into tables in the schema. Files will be loaded into tables with the same name in the schema.
Tables suffixed by a date/time will be loaded incrementally.

## Autoload
The autoload command is used to load the files in the default incoming folder into the datawarehouse.

The autoload command will:
- detect the file type based on its extension and content
- infer the schema of the target table
- stage the files
- load the files into the target tables

Clean the metadata/load folder from any schema you generated previously and run the following command to autoload the files located the incoming folder.

:::warning

autoload will stop short of inferring the schema if the schema file already exists in the metadata/load folder.

:::

```bash
starlake autoload
```

:::note
Starlake looks at files present in the $SL_ROOT/datasets/incoming folder.

The default incoming folder may be changed by setting the SL_INCOMING environment variable.
:::


Once loaded, files are moved to the $SL_ROOT/datasets/archive folder if the SL_ARCHIVE environment variable is set to true (default).
You can replay them by moving them back to the incoming folder.


## Query your datawarehouse
That's it you have loaded the data into your datawarehouse and just need to query it.
To query your database, open de DuckDB shell by running the following command:

:::note
Install [duckdb](https://duckdb.org/docs/installation/) if you haven't done it yet.
:::

```bash
$ cd $SL_ROOT
$ duckdb datasets/duckdb.db
v0.10.0 20b1486d11
Enter ".help" for usage hints.
```

You can now query your datawarehouse using SQL.

```bash
D show;
┌──────────┬──────────┬─────────────────┬──────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────┬───────────┐
│ database │  schema  │      name       │     column_names     │                                           column_types                                            │ temporary │
│ varchar  │ varchar  │     varchar     │      varchar[]       │                                             varchar[]                                             │  boolean  │
├──────────┼──────────┼─────────────────┼──────────────────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┤
│ duckdb   │ audit    │ audit           │ [JOBID, PATHS, DOM…  │ [VARCHAR, VARCHAR, VARCHAR, VARCHAR, BOOLEAN, BIGINT, BIGINT, BIGINT, TIMESTAMP, INTEGER, VARCH…  │ false     │
│ duckdb   │ audit    │ rejected        │ [JOBID, TIMESTAMP,…  │ [VARCHAR, TIMESTAMP, VARCHAR, VARCHAR, VARCHAR, VARCHAR]                                          │ false     │
│ duckdb   │ starbake │ order           │ [customer_id, orde…  │ [BIGINT, BIGINT, VARCHAR, TIMESTAMP]                                                              │ false     │
│ duckdb   │ starbake │ order_line      │ [order_id, product…  │ [BIGINT, BIGINT, BIGINT, DOUBLE]                                                                  │ false     │
│ duckdb   │ starbake │ product         │ [category, cost, d…  │ [VARCHAR, DOUBLE, VARCHAR, VARCHAR, DOUBLE, BIGINT]                                               │ false     │
└──────────┴──────────┴─────────────────┴──────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────┴───────────┘

D select * from starbake.order limit 5;
┌─────────────┬──────────┬───────────┬─────────────────────────┐
│ customer_id │ order_id │  status   │        timestamp        │
│    int64    │  int64   │  varchar  │        timestamp        │
├─────────────┼──────────┼───────────┼─────────────────────────┤
│           6 │        1 │ Cancelled │ 2024-02-05 22:19:15.454 │
│          23 │        2 │ Delivered │ 2024-01-02 11:44:37.59  │
│          20 │        3 │ Delivered │ 2024-02-10 23:10:30.685 │
│           6 │        4 │ Delivered │ 2024-01-17 19:31:22.917 │
│          17 │        5 │ Pending   │ 2024-01-19 01:26:06.674 │
└─────────────┴──────────┴───────────┴─────────────────────────┘
```

To exit the DuckDB shell, type `.quit` and press Enter.

```bash
D .quit
$
```

## Manual load

The autoload command above is a shortcut to the infer-schema, stage and load commands below.
If you used the autoload command, you can skip this section.

### Infer schema
This is done by running the following command:

```bash
starlake infer-schema --input incoming/starbake/ --clean
```

Your metadata `load` folder should now contain the folder `starbake` with following files:
- products.sl.yml
- orders.sl.yml
- order_lines.yml
- _config.sl.yml

The ìnfer-schema` command has created a schema file for each of the files in the incoming folder trying to detect the schema of the files.
These schema files are used to load the data into the datawarehouse.

In a real life scenario, you may want to review the schema files and adjust them to your needs.

### Stage before loading
starlake can stage the files before loading them into the datawarehouse.
This is useful when your files arrive in a different folder from the one where they are loaded into the datawarehouse.

To move the incoming files to the stage folder. Run the following command:

```bash
starlake stage
```


### Load data into your datawarehouse

Run the following command to load the files in the incoming folder.
Since we are target the DuckDB datawarehouse, we need to set the SL_ENV variable to `DUCKDB` to activate the env.DUCKDB.sl.yml configuration file.

```bash

SL_ENV=DUCKDB starlake load

```

Our raw files have been loaded into the datawarehouse and we can now start to [transform our data to build insights](../transform/tutorial).

## Frequently Asked Questions

### What file formats does Starlake support for loading?
Starlake supports loading CSV, TSV, JSON, XML, Fixed-width, Parquet, and Avro files. The file format is auto-detected based on the file extension and content when using the `autoload` command.

### What is the difference between autoload and load in Starlake?
The `autoload` command is a shortcut that combines `infer-schema`, `stage`, and `load` into a single step. It automatically detects file types, infers schemas, and loads data. The manual `load` command requires you to run `infer-schema` and `stage` separately before loading.

### Does Starlake validate data during loading?
Yes, Starlake automatically validates data against the inferred or user-defined schema during loading. Rejected records are stored in a separate audit table, and successfully validated records are loaded into the target table.

### Where do files go after being loaded by Starlake?
Once loaded, files are moved to the `$SL_ROOT/datasets/archive` folder if the `SL_ARCHIVE` environment variable is set to true (which is the default). You can replay them by moving them back to the incoming folder.

