---
title: "Incremental Data Extraction with Starlake"
description: "Configure incremental extraction in Starlake to pull only new rows from a database. Set partitionColumn and fullExport in YAML. State is tracked in the SL_LAST_EXPORT audit table."
keywords: [starlake, incremental extraction, partitionColumn, fullExport, CDC, data sync]
---

import Head from '@docusaurus/Head';

<Head>
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "FAQPage",
      "mainEntity": [
        {
          "@type": "Question",
          "name": "What is the difference between fullExport true and false in Starlake?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "With fullExport: true (default), Starlake extracts the entire table on every run. With fullExport: false, only rows where the partitionColumn value exceeds the last exported value are extracted."
          }
        },
        {
          "@type": "Question",
          "name": "What column types are suitable for partitionColumn?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "The column must be monotonically increasing and never updated after insertion. Typical choices are: auto-increment keys (order_id), timestamps (created_at, updated_at), or sequence numbers."
          }
        },
        {
          "@type": "Question",
          "name": "Where does Starlake store the last extraction state?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "The state is stored in the SL_LAST_EXPORT audit table. Starlake records the maximum value of the partitionColumn after each extraction."
          }
        },
        {
          "@type": "Question",
          "name": "What happens during the first incremental extraction?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Since no prior state exists, Starlake extracts all rows from the table. It then records the maximum partitionColumn value for subsequent runs."
          }
        },
        {
          "@type": "Question",
          "name": "Are updated rows detected in incremental mode?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "No. Incremental mode only detects new rows (partitionColumn value greater than the last export). Modified rows are not re-extracted unless the partition column is an updated_at timestamp."
          }
        },
        {
          "@type": "Question",
          "name": "Can you combine incremental and parallel extraction?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Yes. When fullExport: false and numPartitions > 1 are configured, the same partitionColumn is used for both parallel partitioning and incremental tracking."
          }
        }
      ]
    })}
  </script>
</Head>

# Incremental Data Extraction

Incremental extraction is useful when you want to extract only the data that has changed since the last extraction.
This is especially valuable when you have a large dataset and only a small portion of the data changes frequently.

## Key Configuration Options

### `partitionColumn`

The `partitionColumn` identifies the column used to detect new rows since the last extraction. Starlake records the maximum value of this column after each extraction and uses it as the starting point for the next run. This column should be:

- Monotonically increasing (e.g., an auto-increment ID or a timestamp)
- Never updated after insertion (otherwise changed rows may be missed)

Typical choices include surrogate keys (`order_id`), timestamps (`created_at`, `updated_at`), or sequence numbers.

### `fullExport`

- **`fullExport: true`** (default): Extracts the entire table every time. Use this when the table is small or when you need a complete snapshot.
- **`fullExport: false`**: Enables incremental mode. Only rows where `partitionColumn > last_exported_value` are extracted.

## Configuration

```yaml {8,9} title="metadata/extract/my_extract_config.sl.yml"
version: 1
extract:
  connectionRef: "duckdb" # The database connection to use
  jdbcSchemas:
    - schema: "starbake"
      tables:
        - name: "order"               # table names or  "*" to extract all tables
          fullExport: false           # Enable incremental extraction
          partitionColumn: "order_id" # Column to track extraction progress
  ...
```

## Example Workflow

**First extraction** -- no prior state exists, so Starlake extracts all rows:

```shell
$ starlake extract-data --config my_extract_config --outputDir $SL_ROOT/incoming/
# Extracts all rows from starbake.order
# Records max(order_id) = 1000 in SL_LAST_EXPORT
```

**Subsequent extraction** -- Starlake reads the last exported value and only fetches new rows:

```shell
$ starlake extract-data --config my_extract_config --outputDir $SL_ROOT/incoming/
# Extracts only rows where order_id > 1000
# Updates max(order_id) = 1050 in SL_LAST_EXPORT
```

The extraction state is stored in the `SL_LAST_EXPORT` audit table. See the [Monitoring](./monitoring) page for details on how to inspect this table.
